# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/00_baseline.ipynb.

# %% auto 0
__all__ = ['ds_dir', 'transform', 'create_image_file_list', 'create_labels_file_list', 'create_dataset_list', 'print_ds_info',
           'get_dataset_resolution_stats', 'load_image', 'resize_images', 'extract_hog_features_from_list',
           'calculate_accuracy', 'evaluate', 'extract_lbp_features', 'extract_lbp_features_from_list', 'feature_fusion',
           'test_imbalanced_forest_classifier', 'reduce_hog_features', 'extract_hsv_features_from_list',
           'split_dataset', 'build_augmented_train_dataset', 'build_augmented_train_dataset_pipeline']

# %% ../notebooks/00_baseline.ipynb 2
import sys
import os

from pathlib import Path
import os
import json
import IPython
import matplotlib.pyplot as plt
from skimage.feature import hog
from random import randint
from PIL import Image
from skimage import data, exposure
from skimage.color import rgb2hsv
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import numpy as np
import gc
import pandas as pd
import math

# %% ../notebooks/00_baseline.ipynb 4
ds_dir = Path("../data")
ds_dir.absolute()

# %% ../notebooks/00_baseline.ipynb 7
def create_image_file_list(ds_dir):
    imgs_files = os.listdir(ds_dir.absolute() / "img")
    imgs_files_path = ds_dir / "img"

    imgs_ds = []
    for f in imgs_files:
        imgs_ds.append(os.path.join(ds_dir, f"img/{f}"))
    imgs_ds.sort()
    return imgs_ds

# %% ../notebooks/00_baseline.ipynb 10
def create_labels_file_list(ds_dir):
    lbls_files = os.listdir(ds_dir.absolute() / "ann")
    lbls_files_path = ds_dir / "ann"

    lbls_ds = []
    for f in lbls_files:
        lbls_ds.append(os.path.join(ds_dir, f"ann/{f}"))
    lbls_ds.sort()
    return lbls_ds

# %% ../notebooks/00_baseline.ipynb 13
def create_dataset_list(ds_dir=ds_dir):
    images_list = create_image_file_list(ds_dir)
    labels_list = create_labels_file_list(ds_dir)
    # Create dataset list[<img file>, <label>]
    ds = []
    for img, lbl in zip(images_list, labels_list):
        with open(lbl) as f:
            l = ""
            d = str(json.load(f))
            if "weed" in d:
                l = "weed"
            elif "crop" in d:
                l = "crop"
            ds.append([img, l])
    return ds

# %% ../notebooks/00_baseline.ipynb 15
def print_ds_info(ds):
    # How many of each {weed, crop}
    nof_weeds = len([row[1] for row in ds if row[1] == "weed"])
    nof_crops = len([row[1] for row in ds if row[1] == "crop"])
    print(f"Nof weed samples: {nof_weeds}")
    print(f"Nof crop samples: {nof_crops}")

# %% ../notebooks/00_baseline.ipynb 21
from PIL import Image

def get_dataset_resolution_stats(ds):
    """
    Analyzes the dataset to find min, max, and average resolutions.
    """
    widths = []
    heights = []
    
    for each_img in ds:
        with Image.open(each_img[0]) as img:
            w, h = img.size
            widths.append(w)
            heights.append(h)

    stats = {
        "min": (min(widths), min(heights)),
        "max": (max(widths), max(heights)),
        "avg": (sum(widths)//len(widths), sum(heights)//len(heights))
    }
    
    print(f"Stats: {stats}")
    return stats

# %% ../notebooks/00_baseline.ipynb 24
from skimage import io, img_as_float

def load_image(ds):
    """
    Loads images into memory and converts to float [0, 1] range.
    """
    
    imgs = []
    c = 0
    for record in ds:
        img_path = record[0]
        img = io.imread(img_path) # normalized range is 0-1
        imgs.append(img_as_float(img))
        
    return imgs

# %% ../notebooks/00_baseline.ipynb 29
from skimage.transform import resize

def resize_images(imgs, target_size=(256, 256)):
    """
    Standardizes a list of images to a uniform resolution.
    """
    
    resized_imgs = []
    for img in imgs:
        resized_imgs.append(resize(img, target_size, anti_aliasing=True))
    return resized_imgs

# %% ../notebooks/00_baseline.ipynb 39
from skimage.feature import hog
from skimage.color import rgb2gray

def extract_hog_features_from_list(X_images_rgb):
    """
    Takes a list of pre-resized RGB images and returns HOG features.
    """
    
    X_hog_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray using skimage
        img_gray = rgb2gray(img_rgb)

        # 2. Extract HOG
        hog_features = hog(
            img_gray,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            visualize=False
        )

        X_hog_features.append(hog_features)
        
    return np.array(X_hog_features)

# %% ../notebooks/00_baseline.ipynb 59
def calculate_accuracy(y_test, y_preds):
    accuracy = accuracy_score(y_test, y_preds)
    return accuracy

# %% ../notebooks/00_baseline.ipynb 60
def evaluate(y_test, y_preds, print_cnfm=False):
    """
    RUn the evaluation on the model predictions.
    INPUTS:
        - y_test
        - y_preds
        - print_cnfm=False
    """

    # Accuracy sklearn
    accuracy_sklearn = calculate_accuracy(y_test, y_preds)
    
    # Confusion matrix
    conf_matrix = confusion_matrix(y_test, y_preds)
    
    # Accuracy custom
    accuracy_custom = sum(conf_matrix.diagonal())/sum(conf_matrix.flatten())
    
    # Class recall
    recall_crop = conf_matrix[0][0]/conf_matrix[0].flatten().sum()
    recall_weed = conf_matrix[1][1]/conf_matrix[1].flatten().sum()

    # Class precision
    precision_crop = conf_matrix[0][0]/conf_matrix[:,0].sum()
    if math.isnan(precision_crop):
        precision_crop = 0
    precision_weed = conf_matrix[1][1]/conf_matrix[:,1].sum()

    # Class f1 score
    f1_score_crop = (2*precision_crop*recall_crop)/(precision_crop+recall_crop)
    if math.isnan(f1_score_crop):
        f1_score_crop = 0
    f1_score_weed = (2*precision_weed*recall_weed)/(precision_weed+recall_weed)
    
    
    # F1 macro score
    f1_macro = (f1_score_crop + f1_score_weed) / 2
    
    if print_cnfm == True:
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False, 
            xticklabels=["crop", "weed"], yticklabels=["crop", "weed"])

        plt.title('Confusion Matrix Heatmap')
        plt.xlabel('Predicted Labels')
        plt.ylabel('True Labels')
        plt.show()
    
    
    return {
        "Accuracy sklearn": accuracy_sklearn,
        "Accuracy custom": accuracy_custom,
        "Conf Matrix": conf_matrix,
        "Recall crop": recall_crop,
        "Recall weed": recall_weed,
        "Precision crop: (TP/(TP+FP))": precision_crop,
        "Precision weed": precision_weed,
        "F1 crop": f1_score_crop,
        "F1 weed": f1_score_weed,
        "F1 macro": f1_macro,
    }

# %% ../notebooks/00_baseline.ipynb 83
from skimage import feature

def extract_lbp_features(ds):
    """
    This original version uses OpenCV to laod the image. OpenCV uses the BGR color format.
    
    See newer version instead!
    """
    
    X_lbp_features, y_lbp_labels = [], []
    min_width, min_height = weedcrop.dataset.find_min_dim(ds)
    
    for i in range(len(ds)):
        img = cv2.imread(ds[i][0])
        img_resized = cv2.resize(img, (min_width, min_height))
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)

        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)        

        # Collect features and labels
        X_lbp_features.append(lbp_hist)
        y_lbp_labels.append(ds[i][1])
    return X_lbp_features, y_lbp_labels

# %% ../notebooks/00_baseline.ipynb 86
from skimage import feature, color
import numpy as np

def extract_lbp_features_from_list(X_images_rgb):
    """
    Standardized LBP extraction using pre-resized RGB images.
    """
    
    X_lbp_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray
        img_gray = color.rgb2gray(img_rgb)

        # 2. Extract LBP
        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        
        # 3. Create Histogram (10 bins for P=8 uniform)
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)

        X_lbp_features.append(lbp_hist)
        
    return np.array(X_lbp_features)

# %% ../notebooks/00_baseline.ipynb 99
def feature_fusion(super_matrix:np.ndarray=None, feature_list:list =[]):
    """
    Fuses a list of features into a super-matrix.
    """
    
    new_features = [np.array(f) for f in feature_list]
    
    if super_matrix is None:
        super_matrix = np.hstack([ np.array(f) for f in feature_list ])
        
    else:
        super_matrix = np.hstack([super_matrix] + new_features)
        
    return super_matrix

# %% ../notebooks/00_baseline.ipynb 125
from imblearn.ensemble import BalancedRandomForestClassifier

def test_imbalanced_forest_classifier(X_features:list, y_labels:list, train_split:float=0.8, class_weight=None):
    
    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(
        X_features,
        y_labels,
        train_size=train_split,
        stratify=y_labels, # Fix imbalance
        random_state=42
    )
    
    # Train model
    model = BalancedRandomForestClassifier(n_estimators=100, sampling_strategy="all", replacement=True, class_weight=class_weight)
    model.fit(X_train, y_train)
    
    # Run preds
    y_preds = model.predict(X_test)
    
    # Evaluate
    return evaluate(y_test, y_preds, print_cnfm=True)

# %% ../notebooks/00_baseline.ipynb 140
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def reduce_hog_features(X_hog_features, nof_components=800, fitted_scaler=None, fitted_pca=None):
    """
    Run PCA to reduce HOG features.
    fitted_scaler and fitted_pca variables are for test dataset
    """
    
    if fitted_scaler is None or fitted_pca is None:
        # --- TRAINING MODE ---
        scaler = StandardScaler()
        pca = PCA(n_components=nof_components)
        
        X_scaled = scaler.fit_transform(X_hog_features)
        X_reduced = pca.fit_transform(X_scaled)
        
        return X_reduced, scaler, pca
    else:
        # --- TESTING MODE ---
        # Use the "Rules" we learned from training
        X_scaled = fitted_scaler.transform(X_hog_features)
        X_reduced = fitted_pca.transform(X_scaled)
        
        return X_reduced

# %% ../notebooks/00_baseline.ipynb 155
from skimage import feature, color
import numpy as np

def extract_hsv_features_from_list(X_images_rgb, hue_lower_bound=0.2, hue_upper_bound=0.45, sat_lower=0.25, bins=10):
    """
    Standardized HSV extraction using pre-resized RGB images.
    """
    
    X_hsv_features = []
    
    for img_rgb in X_images_rgb:
        
        # 1. Extract channels
        hsv_img = rgb2hsv(img_rgb)
        hue_chan = hsv_img[:, :, 0]
        sat_chan = hsv_img[:, :, 1]
        val_chan = hsv_img[:, :, 2]

        # 2. Build mask
        hsv_mask = (hue_chan > hue_lower_bound) & (hue_chan < hue_upper_bound) & (sat_chan > sat_lower)
        
        # 3. Apply mask
        plant_hue = hue_chan[hsv_mask]
        plant_sat = sat_chan[hsv_mask]
        plant_val = val_chan[hsv_mask]

        # 4. Create Histogram for each channel
        if plant_hue.size > 0:
            hue_hist, _ = np.histogram(plant_hue, bins=bins, range=(0, 1), density=True)
            sat_hist, _ = np.histogram(plant_sat, bins=bins, range=(0, 1), density=True)
            val_hist, _ = np.histogram(plant_val, bins=bins, range=(0, 1), density=True)
        else:
#             print("Zeroed image")
            hue_hist = np.zeros(bins)
            sat_hist = np.zeros(bins)
            val_hist = np.zeros(bins)

        # 5. Combine channels into one vector
        hsv_vector = np.concatenate([hue_hist, sat_hist, val_hist]) # Flat
        
        # 6. Append to feature list
        X_hsv_features.append(hsv_vector)
        
    return np.array(X_hsv_features)

# %% ../notebooks/00_baseline.ipynb 193
# Build augmentation pipeline
# Parameters as found online
transform = A.Compose([
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=45, p=0.8),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.GaussianBlur(blur_limit=(3, 5), p=0.1),
#     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
    A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
])

transform.set_random_seed(42)

# %% ../notebooks/00_baseline.ipynb 199
from sklearn.model_selection import train_test_split


def split_dataset(X_rez, y_labels, train_size=0.8):
    """
    Split data set in: X_train, X_test, y_train, y_test.
    """
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_rez,
        y_labels,
        train_size=train_size,
        stratify=y_labels, # Fix imbalance
        random_state=42
    )
    return X_train, X_test, y_train, y_test

# %% ../notebooks/00_baseline.ipynb 200
import albumentations as A


def build_augmented_train_dataset(X_train_orig, y_train_orig, transform=None, nof_transforms=3):
    """
    Builds augmented training dataset on the "crop" class.
    """
    
    X_train_aug = []
    y_train_aug = []
    
    if not transform:
        transform = A.Compose([
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=45, p=0.8),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.GaussianBlur(blur_limit=(3, 5), p=0.1),
    #     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
        A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
        ])
    transform.set_random_seed(42)
    
    # Loop through the original split
    for img, label in zip(X_train_orig, y_train_orig):
        if label == "weed":
            # Keep weeds as they are
            X_train_aug.append(img)
            y_train_aug.append("weed")
        else:
            # It's a crop! 
            # Add the original
            X_train_aug.append(img)
            y_train_aug.append("crop")

            # Augment/Transform
            for _ in range(nof_transforms):
                aug_img = transform(image=img.astype("float32"))["image"]
                # Convert back to uint8 for feature extraction later
                aug_img = np.clip(aug_img, 0, 255).astype("uint8")

                X_train_aug.append(aug_img)
                y_train_aug.append("crop")
                
    return X_train_aug, y_train_aug

# %% ../notebooks/00_baseline.ipynb 205
def build_augmented_train_dataset_pipeline(X_rez, y_labels, train_size=0.8, transform=None, nof_transforms=3):
    
    """
    Pipeline for the augmentaiton process.
    """
    
    # Split datasets
    X_train, X_test, y_train, y_test = split_dataset(X_rez, y_labels, train_size=train_size)
    
    # Call augmentations
    X_train_aug, y_train_aug = build_augmented_train_dataset(X_train, y_train, transform=transform, nof_transforms=nof_transforms)
    
    # Return augmented ds
    return X_train_aug, X_test, y_train_aug, y_test
