{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea047a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14581c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Path to the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import weedcrop.dataset as weedcrop_ds\n",
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "148530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = weedcrop_ds.create_dataset_list()\n",
    "ds_list;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad3f3a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f5681",
   "metadata": {},
   "source": [
    "# Resize images to dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d16f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "min_width, min_height = 2000, 2000\n",
    "\n",
    "def find_min_dim(ds):\n",
    "    \"\"\"\n",
    "    Finds the smallest width and height in the dataset using PIL.\n",
    "    \"\"\"\n",
    "    min_width, min_height = 2000, 2000\n",
    "    for each_img in ds:\n",
    "        img = Image.open(each_img[0]) # PIL - RGB/RGBA by default\n",
    "        min_width = min(min_width, img.size[0])\n",
    "        min_height = min(min_height, img.size[1])\n",
    "\n",
    "    print(f\"Minimum resolution: {min_width, min_height}\")\n",
    "    return min_width, min_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e738d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def resize_img_to_dim(img_file_path, width, height):\n",
    "    \"\"\"\n",
    "    Loads image with CV2, converts to RGB, and resizes.\n",
    "    \"\"\"\n",
    "    img_bgr = cv2.imread(img_file_path) # CV2 reads in BGR by default\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (width, height))\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ca0a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a31ebe",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Graphs\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract HOG\n",
    "5. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a655874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def extract_hog_features_from_list(X_images_rgb, y_labels):\n",
    "    \"\"\"\n",
    "    Takes a list of pre-resized RGB images and returns HOG features.\n",
    "    \"\"\"\n",
    "    X_hog_features = []\n",
    "    \n",
    "    for img_rgb in X_images_rgb:\n",
    "        # 1. Convert our standard RGB to Gray using skimage\n",
    "        # This ensures the same weights are used as in your other skimage functions\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "\n",
    "        # 2. Extract HOG\n",
    "        hog_features = hog(\n",
    "            img_gray,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2),\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "        X_hog_features.append(hog_features)\n",
    "        \n",
    "    return np.array(X_hog_features), np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b31099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.7 s, sys: 1.03 s, total: 38.7 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_hog, y_hog = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ae11540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_hog), len(y_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "011538cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28475655, 0.        , 0.02391007, ..., 0.18594874, 0.25146204,\n",
       "        0.25146204]),\n",
       " 'weed')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hog[0], y_hog[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196679f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a5fd2",
   "metadata": {},
   "source": [
    "# Local Binary Pattern - LBP\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract LBP\n",
    "5. Get the histogram of LBP\n",
    "6. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c805c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage import feature, color\n",
    "import numpy as np\n",
    "\n",
    "def extract_lbp_features_from_list(X_images_rgb, y_labels):\n",
    "    \"\"\"\n",
    "    Standardized LBP extraction using pre-resized RGB images.\n",
    "    \"\"\"\n",
    "    X_lbp_features = []\n",
    "    \n",
    "    for img_rgb in X_images_rgb:\n",
    "        # 1. Convert our standard RGB to Gray\n",
    "        # Using skimage.color ensures consistency across the whole project\n",
    "        img_gray = color.rgb2gray(img_rgb)\n",
    "\n",
    "        # 2. Extract LBP\n",
    "        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')\n",
    "        \n",
    "        # 3. Create Histogram (10 bins for P=8 uniform)\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
    "\n",
    "        X_lbp_features.append(lbp_hist)\n",
    "        \n",
    "    return np.array(X_lbp_features), np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c476e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.8 s, sys: 1.05 s, total: 38.9 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_lbp, y_lbp = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "825c893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_lbp), len(y_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f41d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bd7e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def feature_fusion(super_matrix=None, feature_list=[]):\n",
    "    \"\"\" Fuses a list of features into a super-matrix. \"\"\"\n",
    "    \n",
    "    new_features = [np.array(f) for f in feature_list]\n",
    "    \n",
    "    if super_matrix is None:\n",
    "        super_matrix = np.hstack([ np.array(f) for f in feature_list ])\n",
    "        \n",
    "    else:\n",
    "        super_matrix = np.hstack([super_matrix] + new_features)\n",
    "        \n",
    "    return super_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096d3d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# HSV Histograms\n",
    "\n",
    "HOG and LBP capture Shape and Texture, but they ignore Color. In weed-crop datasets, color is often the most discriminative feature (e.g., specific shades of green or the absence of green in soil).\n",
    "\n",
    "Objects are represented by RGB values.\n",
    "\n",
    "In RGB space hue and luminocity are represented as linear combination of the RGB channels. \n",
    "\n",
    "Image segmentation can be performed by value thresholding of the HSV values.\n",
    "    \n",
    "Ref: https://scikit-image.org/docs/0.25.x/auto_examples/color_exposure/plot_rgb_to_hsv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5506a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "\n",
    "def extract_hsv_features_from_list(X_images_resized, bins=16):\n",
    "    \"\"\"\n",
    "    Extracts H, S, and V histograms from the pre-resized RGB image list.\n",
    "    \"\"\"\n",
    "    X_hsv_features = []\n",
    "    \n",
    "    for img_rgb in X_images_resized:\n",
    "        # Convert to HSV (skimage expects RGB, values 0-1)\n",
    "        hsv_img = rgb2hsv(img_rgb)\n",
    "        \n",
    "        # Split channels\n",
    "        h_chan = hsv_img[:, :, 0]\n",
    "        s_chan = hsv_img[:, :, 1]\n",
    "        v_chan = hsv_img[:, :, 2]\n",
    "\n",
    "        # Calculate histograms for each channel\n",
    "        # We use density=True to normalize the vectors\n",
    "        h_hist, _ = np.histogram(h_chan, bins=bins, range=(0, 1), density=True)\n",
    "        s_hist, _ = np.histogram(s_chan, bins=bins, range=(0, 1), density=True)\n",
    "        v_hist, _ = np.histogram(v_chan, bins=bins, range=(0, 1), density=True)\n",
    "\n",
    "        # Combine H, S, and V into one feature vector for this image\n",
    "        hsv_vector = np.concatenate([h_hist, s_hist, v_hist]) # Flat vector\n",
    "        X_hsv_features.append(hsv_vector)\n",
    "        \n",
    "    return np.array(X_hsv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323692c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13e02e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "\n",
    "def extract_masked_hsv_features(X_images_resized, bins=16):\n",
    "    \"\"\"\n",
    "    Extracts HSV histograms ONLY from pixels identified as 'Plant' \n",
    "    based on Hue and Value thresholds.\n",
    "    \"\"\"\n",
    "    X_hsv_features = []\n",
    "    \n",
    "    for img_rgb in X_images_resized:\n",
    "        # 1. Convert to HSV\n",
    "        hsv_img = rgb2hsv(img_rgb)\n",
    "        h, s, v = hsv_img[:,:,0], hsv_img[:,:,1], hsv_img[:,:,2]\n",
    "        \n",
    "        # 2. Apply your \"Plant Discovery\" Mask\n",
    "        # We only look at 'Green' hues (0.2 - 0.45) and skip dark shadows (v > 0.1)\n",
    "        mask = (h > 0.2) & (h < 0.45) & (v > 0.1)\n",
    "        \n",
    "        # 3. Extract pixels that belong to the plant\n",
    "        # This collapses the 2D image into a 1D list of 'Plant' pixels\n",
    "        plant_h = h[mask]\n",
    "        plant_s = s[mask]\n",
    "        plant_v = v[mask]\n",
    "\n",
    "        # 4. Handle edge case: if no plant is detected, return zeros\n",
    "        if len(plant_h) > 0:\n",
    "            h_hist, _ = np.histogram(plant_h, bins=bins, range=(0, 1), density=True)\n",
    "            s_hist, _ = np.histogram(plant_s, bins=bins, range=(0, 1), density=True)\n",
    "            v_hist, _ = np.histogram(plant_v, bins=bins, range=(0, 1), density=True)\n",
    "        else:\n",
    "            h_hist = np.zeros(bins)\n",
    "            s_hist = np.zeros(bins)\n",
    "            v_hist = np.zeros(bins)\n",
    "\n",
    "        # 5. Combine and append\n",
    "        hsv_vector = np.concatenate([h_hist, s_hist, v_hist])\n",
    "        X_hsv_features.append(hsv_vector)\n",
    "        \n",
    "    return np.array(X_hsv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3106a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data-Level: Augmentation (Not just SMOTE)\n",
    "\n",
    "\"Feature engineering on the smaller class to increase its size\" is exactly what you should do, but be careful with SMOTE. SMOTE creates \"average\" versions of your 60 samples in feature space, which can sometimes just create noise.\n",
    "\n",
    "Better approach: Image Augmentation. Before extracting HOG/LBP, take your 60 crop images and create 10 new versions of each by:\n",
    "\n",
    "    Rotating them (90°, 180°, 270°).\n",
    "\n",
    "    Flipping them horizontally and vertically.\n",
    "\n",
    "    Adjusting Brightness slightly.\n",
    "\n",
    "This turns your 60 samples into 600 samples of real visual data. Extract HOG/LBP from these augmented images. This is much more robust for computer vision than purely mathematical oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929f246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
