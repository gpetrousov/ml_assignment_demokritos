{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67f93258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14581c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Path to the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import weedcrop.dataset as weedcrop_ds\n",
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "148530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = weedcrop_ds.create_dataset_list()\n",
    "ds_list;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66d0ab",
   "metadata": {},
   "source": [
    "# Resize images to dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f7f3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "min_width, min_height = 2000, 2000\n",
    "\n",
    "def find_min_dim(ds):\n",
    "    \"\"\"\n",
    "    Finds the smallest width and height in the dataset using PIL.\n",
    "    \"\"\"\n",
    "    min_width, min_height = 2000, 2000\n",
    "    for each_img in ds:\n",
    "        img = Image.open(each_img[0]) # PIL - RGB/RGBA by default\n",
    "        min_width = min(min_width, img.size[0])\n",
    "        min_height = min(min_height, img.size[1])\n",
    "\n",
    "    print(f\"Minimum resolution: {min_width, min_height}\")\n",
    "    return min_width, min_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1f7221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def resize_img_to_dim(img_file_path, width, height):\n",
    "    \"\"\"\n",
    "    Loads image with CV2, converts to RGB, and resizes.\n",
    "    \"\"\"\n",
    "    img_bgr = cv2.imread(img_file_path) # CV2 reads in BGR by default\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (width, height))\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a31ebe",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Graphs\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract HOG\n",
    "5. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a655874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def extract_hog_features_from_list(X_images_rgb, y_labels):\n",
    "    \"\"\"\n",
    "    Takes a list of pre-resized RGB images and returns HOG features.\n",
    "    \"\"\"\n",
    "    X_hog_features = []\n",
    "    \n",
    "    for img_rgb in X_images_rgb:\n",
    "        # 1. Convert our standard RGB to Gray using skimage\n",
    "        # This ensures the same weights are used as in your other skimage functions\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "\n",
    "        # 2. Extract HOG\n",
    "        hog_features = hog(\n",
    "            img_gray,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2),\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "        X_hog_features.append(hog_features)\n",
    "        \n",
    "    return np.array(X_hog_features), np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b31099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.7 s, sys: 1.03 s, total: 38.7 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_hog, y_hog = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ae11540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_hog), len(y_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "011538cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28475655, 0.        , 0.02391007, ..., 0.18594874, 0.25146204,\n",
       "        0.25146204]),\n",
       " 'weed')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hog[0], y_hog[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7d909",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a5fd2",
   "metadata": {},
   "source": [
    "# Local Binary Pattern - LBP\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract LBP\n",
    "5. Get the histogram of LBP\n",
    "6. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c805c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from skimage import feature, color\n",
    "import numpy as np\n",
    "\n",
    "def extract_lbp_features_from_list(X_images_rgb, y_labels):\n",
    "    \"\"\"\n",
    "    Standardized LBP extraction using pre-resized RGB images.\n",
    "    \"\"\"\n",
    "    X_lbp_features = []\n",
    "    \n",
    "    for img_rgb in X_images_rgb:\n",
    "        # 1. Convert our standard RGB to Gray\n",
    "        # Using skimage.color ensures consistency across the whole project\n",
    "        img_gray = color.rgb2gray(img_rgb)\n",
    "\n",
    "        # 2. Extract LBP\n",
    "        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')\n",
    "        \n",
    "        # 3. Create Histogram (10 bins for P=8 uniform)\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
    "\n",
    "        X_lbp_features.append(lbp_hist)\n",
    "        \n",
    "    return np.array(X_lbp_features), np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c476e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.8 s, sys: 1.05 s, total: 38.9 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_lbp, y_lbp = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "825c893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_lbp), len(y_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60207acc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9fdb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def feature_fusion(super_matrix=None, feature_list=[]):\n",
    "    \"\"\" Fuses a list of features into a super-matrix. \"\"\"\n",
    "    \n",
    "    new_features = [np.array(f) for f in feature_list]\n",
    "    \n",
    "    if super_matrix is None:\n",
    "        super_matrix = np.hstack([ np.array(f) for f in feature_list ])\n",
    "        \n",
    "    else:\n",
    "        super_matrix = np.hstack([super_matrix] + new_features)\n",
    "        \n",
    "    return super_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903b0f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# HSV Histograms\n",
    "\n",
    "HOG and LBP capture Shape and Texture, but they ignore Color. In weed-crop datasets, color is often the most discriminative feature (e.g., specific shades of green or the absence of green in soil).\n",
    "\n",
    "Objects are represented by RGB values.\n",
    "\n",
    "In RGB space hue and luminocity are represented as linear combination of the RGB channels. \n",
    "\n",
    "Image segmentation can be performed by value thresholding of the HSV values.\n",
    "    \n",
    "Ref: https://scikit-image.org/docs/0.25.x/auto_examples/color_exposure/plot_rgb_to_hsv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9aa23613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667cf74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2481a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458c668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f417ec1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data-Level: Augmentation (Not just SMOTE)\n",
    "\n",
    "\"Feature engineering on the smaller class to increase its size\" is exactly what you should do, but be careful with SMOTE. SMOTE creates \"average\" versions of your 60 samples in feature space, which can sometimes just create noise.\n",
    "\n",
    "Better approach: Image Augmentation. Before extracting HOG/LBP, take your 60 crop images and create 10 new versions of each by:\n",
    "\n",
    "    Rotating them (90°, 180°, 270°).\n",
    "\n",
    "    Flipping them horizontally and vertically.\n",
    "\n",
    "    Adjusting Brightness slightly.\n",
    "\n",
    "This turns your 60 samples into 600 samples of real visual data. Extract HOG/LBP from these augmented images. This is much more robust for computer vision than purely mathematical oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
