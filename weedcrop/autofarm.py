# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/00_baseline.ipynb.

# %% auto 0
__all__ = ['ds_dir', 'transform', 'create_ds_path', 'create_image_file_list', 'create_labels_file_list', 'create_dataset_list',
           'print_ds_info', 'get_dataset_resolution_stats', 'load_image', 'resize_images', 'prepare_ds_pipeline',
           'extract_hog_features_from_list', 'calculate_accuracy', 'evaluate', 'extract_lbp_features',
           'extract_lbp_features_from_list', 'feature_fusion', 'test_imbalanced_forest_classifier',
           'reduce_hog_features', 'extract_hsv_features_from_list', 'split_dataset', 'build_augmented_train_dataset',
           'build_augmented_train_dataset_pipeline']

# %% ../notebooks/00_baseline.ipynb 2
import sys
import os

from pathlib import Path
import os
import json
import IPython
import matplotlib.pyplot as plt
from skimage.feature import hog
from random import randint
from PIL import Image
from skimage import data, exposure
from skimage.color import rgb2hsv
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import numpy as np
import gc
import pandas as pd
import math

# %% ../notebooks/00_baseline.ipynb 4
ds_dir = Path("../data")
ds_dir.absolute()

# %% ../notebooks/00_baseline.ipynb 5
def create_ds_path(default_path="../data"):
    """
    Returns the path to the dataset.
    
    INPUTS:
        - default_path ["../data"]: path to root directory of the dataset.
        
    OUTPUTS:
        - ds_dir: dataset directory: type(Path)
    """
    
    ds_dir = Path(default_path)
    ds_dir.absolute()
    return ds_dir

# %% ../notebooks/00_baseline.ipynb 8
def create_image_file_list(ds_dir):
    """
    Returns the dataset with the images in a list.
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
               
    OUTPUTS:
        - imgs_ds: dataset with images: type(list)
    """
    
    imgs_files = os.listdir(ds_dir.absolute() / "img")
    imgs_files_path = ds_dir / "img"

    imgs_ds = []
    for f in imgs_files:
        imgs_ds.append(os.path.join(ds_dir, f"img/{f}"))
    imgs_ds.sort()
    return imgs_ds

# %% ../notebooks/00_baseline.ipynb 11
def create_labels_file_list(ds_dir):
    """
    Returns the dataset with the labels in a list.
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
                       
    OUTPUTS:
        - lbls_ds: dataset with labels: type(list)
    """
    
    lbls_files = os.listdir(ds_dir.absolute() / "ann")
    lbls_files_path = ds_dir / "ann"

    lbls_ds = []
    for f in lbls_files:
        lbls_ds.append(os.path.join(ds_dir, f"ann/{f}"))
    lbls_ds.sort()
    return lbls_ds

# %% ../notebooks/00_baseline.ipynb 14
def create_dataset_list(ds_dir):
    """
    Returns the dataset in the format: list[<img file>, <label>]
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
                               
    OUTPUTS:
        - ds: dataset format: list[<img file>, <label>]
    """
    
    images_list = create_image_file_list(ds_dir)
    labels_list = create_labels_file_list(ds_dir)
    # Create dataset list[<img file>, <label>]
    ds = []
    for img, lbl in zip(images_list, labels_list):
        with open(lbl) as f:
            l = ""
            d = str(json.load(f))
            if "weed" in d:
                l = "weed"
            elif "crop" in d:
                l = "crop"
            ds.append([img, l])
    return ds

# %% ../notebooks/00_baseline.ipynb 16
def print_ds_info(ds):
    """
    Prints dataset statistics.
    
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
    """
    
    # How many of each {weed, crop}
    nof_weeds = len([row[1] for row in ds if row[1] == "weed"])
    nof_crops = len([row[1] for row in ds if row[1] == "crop"])
    print(f"Nof weed samples: {nof_weeds}")
    print(f"Nof crop samples: {nof_crops}")

# %% ../notebooks/00_baseline.ipynb 22
from PIL import Image

def get_dataset_resolution_stats(ds):
    """
    Analyzes the dataset to find min, max, and average resolutions.
    
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
        
    OUTPUTS:
        - stats: Resolution statistics: type(dict)
    """
    
    widths = []
    heights = []
    
    for each_img in ds:
        with Image.open(each_img[0]) as img:
            w, h = img.size
            widths.append(w)
            heights.append(h)

    stats = {
        "min": (min(widths), min(heights)),
        "max": (max(widths), max(heights)),
        "avg": (sum(widths)//len(widths), sum(heights)//len(heights))
    }
    
    print(f"Stats: {stats}")
    return stats

# %% ../notebooks/00_baseline.ipynb 25
from skimage import io, img_as_float

def load_image(ds):
    """
    Loads images into memory and converts to float [0, 1] range.
        
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
        
    OUTPUTS:
        - imgs: image list; images are normalized:0-1
    """
    
    imgs = []
    c = 0
    for record in ds:
        img_path = record[0]
        img = io.imread(img_path) # normalized range is 0-1
        imgs.append(img_as_float(img))
        
    return imgs

# %% ../notebooks/00_baseline.ipynb 30
from skimage.transform import resize


def resize_images(imgs, target_size=(256, 256)):
    """
    Standardizes a list of images to a uniform resolution.
        
    INPUTS:
        - imgs: standardized images in a list
        
    OUTPUTS:
        - resized_imgs: resized images in a list
    """
    
    resized_imgs = []
    for img in imgs:
        resized_imgs.append(resize(img, target_size, anti_aliasing=True))
    return resized_imgs

# %% ../notebooks/00_baseline.ipynb 34
def prepare_ds_pipeline():
    """
    Loads images into memory, resizes to target resolution.
    Returns resized images and labels lists.
        
    OUTPUTS:
        - X_rez: resized images in a list
        - y_labels: image labels in a list
    """
    
    # Create path
    ds_dir = create_ds_path()
    
    # Create ds list
    ds = create_dataset_list(ds_dir)
    
    # Load iamges to memory
    X_imgs = load_image(ds)
    
    # Resize to equal size
    X_rez = resize_images(X_imgs)
    
    # Extract labels
    y_labels = [lbl[1] for lbl in ds]
    
    return X_rez, y_labels

# %% ../notebooks/00_baseline.ipynb 43
from skimage.feature import hog
from skimage.color import rgb2gray

def extract_hog_features_from_list(X_images_rgb):
    """
    Takes a list of pre-resized RGB images and returns HOG features.
    
    INPUTS:
        - X_images_rgb: list of images in memory
    
    OUTPUTS:
        - np.array(X_hog_features): Numpy array of HOG features
    """
    
    X_hog_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray using skimage
        img_gray = rgb2gray(img_rgb)

        # 2. Extract HOG
        hog_features = hog(
            img_gray,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            visualize=False
        )

        X_hog_features.append(hog_features)
        
    return np.array(X_hog_features)

# %% ../notebooks/00_baseline.ipynb 63
def calculate_accuracy(y_test, y_preds):
    """
    Simple function to calculate accuracy.
    
    INPUTS:
        - y_test: true labels
        - y_preds: predicted labels
    """
    
    accuracy = accuracy_score(y_test, y_preds)
    return accuracy

# %% ../notebooks/00_baseline.ipynb 64
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import math

def evaluate(y_test, y_preds, y_probs=None, print_cnfm=False):
    """
    Evaluates model performance using classification metrics and PR curves.
    Specifically designed to handle "crop" as the target positive class.
        
    INPUTS:
        - y_test: Ground truth labels
        - y_preds: Predicted class labels
        - y_probs: Probabilities for the "crop" class (Column 0)
        - print_cnfm: Boolean to trigger Confusion Matrix and PR Curve plots
        
    OUTPUTS:
        - metrics: Dictionary containing Accuracy, Recall, Precision, F1, and AUC
    """
    
    
    # Accuracy sklearn
    accuracy_sklearn = calculate_accuracy(y_test, y_preds)
    
    # Confusion matrix
    conf_matrix = confusion_matrix(y_test, y_preds)
    
    # Accuracy custom
    accuracy_custom = sum(conf_matrix.diagonal())/sum(conf_matrix.flatten())
    
    # Class recall
    recall_crop = conf_matrix[0][0]/conf_matrix[0].flatten().sum()
    recall_weed = conf_matrix[1][1]/conf_matrix[1].flatten().sum()

    # Class precision
    precision_crop = conf_matrix[0][0]/conf_matrix[:,0].sum()
    if math.isnan(precision_crop): precision_crop = 0
    precision_weed = conf_matrix[1][1]/conf_matrix[:,1].sum()

    # Class f1 score
    f1_score_crop = (2*precision_crop*recall_crop)/(precision_crop+recall_crop) if (precision_crop+recall_crop) > 0 else 0
    f1_score_weed = (2*precision_weed*recall_weed)/(precision_weed+recall_weed) if (precision_weed+recall_weed) > 0 else 0
    
    # F1 macro score
    f1_macro = (f1_score_crop + f1_score_weed) / 2
    
    metrics = {
        "Accuracy sklearn": accuracy_sklearn,
        "Accuracy custom": accuracy_custom,
        "Conf Matrix": conf_matrix,
        "Recall crop": recall_crop,
        "Recall weed": recall_weed,
        "Precision crop: (TP/(TP+FP))": precision_crop,
        "Precision weed": precision_weed,
        "F1 crop": f1_score_crop,
        "F1 weed": f1_score_weed,
        "F1 macro": f1_macro,
    }

    # AUC and PR Curve
    if y_probs is not None:
        # FIX: To get AUC for "crop", we provide the probabilities and tell sklearn 
        # the order is ["weed", "crop"]. It will treat the second one as the positive class.
        # Since you pass Crop probs, we ensure they are compared against 'crop' labels.
        auc_score = roc_auc_score(y_test, y_probs)
        
        # If the score is low (0.10), it means the internal order is flipped.
        # We handle the crop-specific AUC logic here:
        if auc_score < 0.5:
            auc_score = 1 - auc_score
            
        metrics["AUC score"] = auc_score

        if print_cnfm:
            # Calculate PR Curve data - this DOES accept pos_label
            precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs, pos_label="crop")
            pr_auc = auc(recalls, precisions)

            # Plotting
            fig, ax = plt.subplots(1, 2, figsize=(15, 6))

            # Subplot 1: Confusion Matrix
            sns.heatmap(conf_matrix, annot=True, fmt="g", cmap="Blues", cbar=False, 
                        xticklabels=["crop", "weed"], yticklabels=["crop", "weed"], ax=ax[0])
            ax[0].set_title("Confusion Matrix Heatmap")
            ax[0].set_xlabel("Predicted Labels")
            ax[0].set_ylabel("True Labels")

            # Subplot 2: Precision-Recall Curve
            ax[1].plot(recalls, precisions, label=f"PR Curve (AUC = {pr_auc:.2f})", color="green")
            ax[1].set_title("Precision-Recall Curve (Crop Focus)")
            ax[1].set_xlabel("Recall (Crops Found)")
            ax[1].set_ylabel("Precision (No Weeds Misidentified)")
            ax[1].legend()
            ax[1].grid(True)
            
            plt.tight_layout()
            plt.show()
    
    elif print_cnfm:
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="g", cmap="Blues", cbar=False, 
                    xticklabels=["crop", "weed"], yticklabels=["crop", "weed"])
        plt.title("Confusion Matrix Heatmap")
        plt.show()
    
    return metrics

# %% ../notebooks/00_baseline.ipynb 87
from skimage import feature

def extract_lbp_features(ds):
    """
    DEPRECATED
    This original version uses OpenCV to laod the image. OpenCV uses the BGR color format.
    
    See newer version instead!
    """
    
    X_lbp_features, y_lbp_labels = [], []
    min_width, min_height = dataset.find_min_dim(ds)
    
    for i in range(len(ds)):
        img = cv2.imread(ds[i][0])
        img_resized = cv2.resize(img, (min_width, min_height))
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)

        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)        

        # Collect features and labels
        X_lbp_features.append(lbp_hist)
        y_lbp_labels.append(ds[i][1])
    return X_lbp_features, y_lbp_labels

# %% ../notebooks/00_baseline.ipynb 90
from skimage import feature, color
import numpy as np

def extract_lbp_features_from_list(X_images_rgb):
    """
    Standardized LBP extraction using pre-resized RGB images.
    
    INPUTS
        - X_images_rgb: list of images in memory
        
    OUTPUTS:
        - np.array(X_lbp_features): numpy array of LBP features for each image
    """
    
    X_lbp_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray
        img_gray = color.rgb2gray(img_rgb)

        # 2. Extract LBP
        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        
        # 3. Create Histogram (10 bins for P=8 uniform)
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)

        X_lbp_features.append(lbp_hist)
        
    return np.array(X_lbp_features)

# %% ../notebooks/00_baseline.ipynb 103
def feature_fusion(super_matrix:np.ndarray=None, feature_list:list =[]):
    """
    Fuses multiple feature sets into a single matrix via horizontal stacking.
    Used to combine HOG, LBP, and HSV features into a unified feature vector.
    
    INPUTS:
        - super_matrix: Existing numpy matrix of features (None for first fusion)
        - feature_list: List of feature arrays to be appended to the super_matrix
        
    OUTPUTS:
        - super_matrix: Numpy matrix with features stacked horizontally per image
    """
    
    new_features = [np.array(f) for f in feature_list]
    
    if super_matrix is None:
        super_matrix = np.hstack([ np.array(f) for f in feature_list ])
        
    else:
        super_matrix = np.hstack([super_matrix] + new_features)
        
    return super_matrix

# %% ../notebooks/00_baseline.ipynb 129
from imblearn.ensemble import BalancedRandomForestClassifier

def test_imbalanced_forest_classifier(X_features:list, y_labels:list, train_split:float=0.8, class_weight=None):
    """
    Trains and evaluates a Balanced Random Forest to handle class imbalance.
    Uses stratified splitting to ensure representative class distribution in test sets.
    
    INPUTS:
        - X_features: List or array of fused features
        - y_labels: List of ground truth labels
        - train_split: Float representing the training set size ratio
        - class_weight: Optional dictionary for manual class weighting
        
    OUTPUTS:
        - metrics: Dictionary from evaluate() containing performance results
    """
    
    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(
        X_features,
        y_labels,
        train_size=train_split,
        stratify=y_labels, # Balances sets
        random_state=42
    )
    
    # Train model
    model = BalancedRandomForestClassifier(n_estimators=100, sampling_strategy="all", replacement=True, class_weight=class_weight)
    model.fit(X_train, y_train)
    
    # Run preds
    y_preds = model.predict(X_test)
    
    # Evaluate
    return evaluate(y_test, y_preds, print_cnfm=True)

# %% ../notebooks/00_baseline.ipynb 144
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def reduce_hog_features(X_hog_features, nof_components=800, fitted_scaler=None, fitted_pca=None):
    """
    Applies StandardScaler and PCA to reduce the dimensionality of HOG features.
    Supports both training mode (fitting new rules) and testing mode (applying learned rules).
    
    INPUTS:
        - X_hog_features: Matrix of HOG features to reduce
        - nof_components: Number of dimensions to keep after PCA
        - fitted_scaler: A pre-fitted StandardScaler (None for training mode)
        - fitted_pca: A pre-fitted PCA model (None for training mode)
        
    OUTPUTS:
        - X_reduced: The transformed/reduced feature matrix
        - scaler: The StandardScaler used (fitted or provided)
        - pca: The PCA model used (fitted or provided)
    """
    
    if fitted_scaler is None or fitted_pca is None:
        # --- TRAINING MODE ---
        scaler = StandardScaler()
        pca = PCA(n_components=nof_components)
        
        X_scaled = scaler.fit_transform(X_hog_features)
        X_reduced = pca.fit_transform(X_scaled)
        
        return X_reduced, scaler, pca
    else:
        # --- TESTING MODE ---
        # Use the "Rules" we learned from training
        X_scaled = fitted_scaler.transform(X_hog_features)
        X_reduced = fitted_pca.transform(X_scaled)
        
        return X_reduced

# %% ../notebooks/00_baseline.ipynb 159
from skimage import feature, color
import numpy as np

def extract_hsv_features_from_list(X_images_rgb, hue_lower_bound=0.2, hue_upper_bound=0.45, sat_lower=0.25, bins=10):
    """
    Extracts masked HSV histograms from a list of RGB images.
    Uses color-based thresholding to isolate plant matter from the background.
    
    INPUTS:
        - X_images_rgb: List of RGB images in memory
        - hue_lower_bound: Lower threshold for green hue (default 0.2)
        - hue_upper_bound: Upper threshold for green hue (default 0.45)
        - sat_lower: Minimum saturation to filter out gray/background (default 0.25)
        - bins: Number of histogram bins per channel
        
    OUTPUTS:
        - np.array(X_hsv_features): Numpy array of concatenated H-S-V histograms
    """
    
    X_hsv_features = []
    
    for img_rgb in X_images_rgb:
        
        # 1. Extract channels
        hsv_img = rgb2hsv(img_rgb)
        hue_chan = hsv_img[:, :, 0]
        sat_chan = hsv_img[:, :, 1]
        val_chan = hsv_img[:, :, 2]

        # 2. Build mask
        hsv_mask = (hue_chan > hue_lower_bound) & (hue_chan < hue_upper_bound) & (sat_chan > sat_lower)
        
        # 3. Apply mask
        plant_hue = hue_chan[hsv_mask]
        plant_sat = sat_chan[hsv_mask]
        plant_val = val_chan[hsv_mask]

        # 4. Create Histogram for each channel
        if plant_hue.size > 0:
            hue_hist, _ = np.histogram(plant_hue, bins=bins, range=(0, 1), density=True)
            sat_hist, _ = np.histogram(plant_sat, bins=bins, range=(0, 1), density=True)
            val_hist, _ = np.histogram(plant_val, bins=bins, range=(0, 1), density=True)
        else:
#             print("Zeroed image")
            hue_hist = np.zeros(bins)
            sat_hist = np.zeros(bins)
            val_hist = np.zeros(bins)

        # 5. Combine channels into one vector
        hsv_vector = np.concatenate([hue_hist, sat_hist, val_hist]) # Flat
        
        # 6. Append to feature list
        X_hsv_features.append(hsv_vector)
        
    return np.array(X_hsv_features)

# %% ../notebooks/00_baseline.ipynb 197
# Parameters as found online
transform = A.Compose([
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=30, p=0.2),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.GaussianBlur(blur_limit=(3, 5), p=0.1),
#     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
    A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
])

transform.set_random_seed(42)

# %% ../notebooks/00_baseline.ipynb 203
from sklearn.model_selection import train_test_split


def split_dataset(X_rez, y_labels, train_size=0.8):
    """
    Split data set in: X_train, X_test, y_train, y_test.
    """
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_rez,
        y_labels,
        train_size=train_size,
        stratify=y_labels, # Balances sets
        random_state=42
    )
    return X_train, X_test, y_train, y_test

# %% ../notebooks/00_baseline.ipynb 204
import albumentations as A


def build_augmented_train_dataset(X_train_orig, y_train_orig, transform=None, nof_transforms=3):
    """
    Builds an augmented training dataset by oversampling the "crop" class.
    Applies geometric and color transformations to balance class distribution.
    
    INPUTS:
        - X_train_orig: List of original RGB training images
        - y_train_orig: List of original training labels
        - transform: Albumentations pipeline (uses default if None)
        - nof_transforms: Number of augmented versions to create per crop image
        
    OUTPUTS:
        - X_train_aug: List containing original images plus augmented crops
        - y_train_aug: Updated list of labels for the augmented dataset
    """
    
    X_train_aug = []
    y_train_aug = []
    
    if not transform:
        transform = A.Compose([
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=20, p=0.3),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.GaussianBlur(blur_limit=(3, 5), p=0.1),
    #     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
        A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
        ])
    transform.set_random_seed(42)
    
    # Loop through the original split
    for img, label in zip(X_train_orig, y_train_orig):
        if label == "weed":
            # Keep weeds as they are
            X_train_aug.append(img)
            y_train_aug.append("weed")
        else:
            # It's a crop! 
            # Add the original
            X_train_aug.append(img)
            y_train_aug.append("crop")

            # Augment/Transform
            for _ in range(nof_transforms):
                aug_img = transform(image=img.astype("float32"))["image"]
                # Convert back to uint8 for feature extraction later
                aug_img = np.clip(aug_img, 0, 255).astype("uint8")

                X_train_aug.append(aug_img)
                y_train_aug.append("crop")
                
    return X_train_aug, y_train_aug

# %% ../notebooks/00_baseline.ipynb 209
def build_augmented_train_dataset_pipeline(X_rez, y_labels, train_size=0.8, transform=None, nof_transforms=3):
    """
    Orchestrates the split-then-augment workflow to ensure a valid evaluation.
    Splits the data into training and test sets, then augments only the 
    training portion to address class imbalance.
        
    INPUTS:
        - X_rez: List of resized images in memory
        - y_labels: List of original image labels
        - train_size: Float representing the proportion of data for training
        - transform: Albumentations pipeline for augmentation
        - nof_transforms: Number of augmented copies to generate per "crop" image
        
    OUTPUTS:
        - X_train_aug: Augmented training images
        - X_test: Original (non-augmented) test images
        - y_train_aug: Labels for the augmented training set
        - y_test: Labels for the test set
    """
    
    # Split datasets
    X_train, X_test, y_train, y_test = split_dataset(X_rez, y_labels, train_size=train_size)
    
    # Call augmentations
    X_train_aug, y_train_aug = build_augmented_train_dataset(X_train, y_train, transform=transform, nof_transforms=nof_transforms)
    
    # Return augmented ds
    return X_train_aug, X_test, y_train_aug, y_test
