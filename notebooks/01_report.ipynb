{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56851b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:54: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported from: /home/master/dev/demokritos/ml_assignments/weedcrop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.10/site-packages/albumentations/core/validation.py:132: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 3. Add project to sys.path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# 4. Import your exported functions\n",
    "from weedcrop.autofarm import *\n",
    "\n",
    "# Verification\n",
    "print(f\"Successfully imported from: {project_root / 'weedcrop'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d450cf",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b50587",
   "metadata": {},
   "source": [
    "## 1. Problem definition\n",
    "\n",
    "**Problem definition**\n",
    "\"Classifying crops vs. weeds to enable autonomous herbicide application, focusing on high crop recall to ensure yield safety.\"\n",
    "\n",
    "## 2. Dataset overview\n",
    "\n",
    "**Dataset Overview**\n",
    "Brief description of the data source and the class imbalance (Few crops vs. many weeds).\n",
    "\n",
    "## 3. Exploration / Feature Engineering\n",
    "\n",
    "**The Fusion Logic**\n",
    "Explain why you chose HOG (shape), LBP (texture), and HSV (color).\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "Show the PCA step. Mention that you reduced HOG features to 800 components to prevent the \"Curse of Dimensionality\" in Naive Bayes.\n",
    "\n",
    "**Visualizing Features**\n",
    "Plot a histogram of one feature (e.g., Hue from HSV) comparing Crops and Weeds to show the professor there is a \"correlation\" as requested in Step 3 of the assignment.\n",
    "\n",
    "## 4. Model / Fit (The Optimization)\n",
    "\n",
    "**Baseline Model**\n",
    "Run a quick vanilla GaussianNB to show it fails (high False Positives).\n",
    "\n",
    "**Hyperparameter Grid Search**\n",
    "\n",
    "- Insert your Grid Search code here!!!\n",
    "- Display the Heatmap (Smoothing vs. Weed Weight).\n",
    "\n",
    "Text:\n",
    "The grid search identifies the optimal balance between statistical feature value smoothing and cost-sensitive weighting.\n",
    "\n",
    "## 5. Evaluate / Communicate (The \"Full\" Analysis)\n",
    "\n",
    "- The Surgical Result: Train the final model with best_params.\n",
    "- The PR-Curve & Pinned Threshold:\n",
    "    - Plot the Precision-Recall curve.\n",
    "    - Explain the extraction of the Pinned Threshold\n",
    "- Final Confusion Matrix: evaluate(print_cnfm=True)\n",
    "- Business-Level Metrics: * Translate the matrix into real-world terms: \"Our model saves 91.6% of crops while rejecting 85% of weeds.\"\n",
    "\n",
    "## 6. Conclusions & Future Work\n",
    "\n",
    "By fusing HOG, LBP, and HSV features with a cost-sensitive GaussianNB, we achieved an AUC of 0.90.\n",
    "\n",
    "We enriched the minority samples with transformed images and increased the ratio to X\n",
    "\n",
    "**Future Work**\n",
    "- Naive Bayes is a strong baseline, future iterations could explore the BalancedRandomForestClassifier\n",
    "- PyCaret provides a collection of algorithms to experiment with on the optimized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e48dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ed4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0191bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f74a7ba2",
   "metadata": {},
   "source": [
    "# Experiment GAUSIAN NB classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the grid\n",
    "smoothing_grid = np.logspace(-9, 1, 10) # 1e-9 to 10\n",
    "weight_grid = np.linspace(1.0, 5.0, 10) # 1.0 to 5.0\n",
    "\n",
    "# Storage for results\n",
    "auc_results = np.zeros((len(smoothing_grid), len(weight_grid)))\n",
    "\n",
    "best_auc = 0\n",
    "best_params = {\"smooth\": 0, \"weight\": 0}\n",
    "\n",
    "print(\"Running Grid Search...\")\n",
    "\n",
    "for i, s in enumerate(smoothing_grid):\n",
    "    for j, w in enumerate(weight_grid):\n",
    "        # Prepare weights\n",
    "        iter_weights = np.ones(len(y_train))\n",
    "        iter_weights[hard_weed_indices] = w\n",
    "        \n",
    "        # Train and get metrics using your experiment function\n",
    "        # Using print_cnfm=False to stay fast\n",
    "        m, _ = experiment_gaussian_nb(X_train, y_train, X_test, y_test, \n",
    "                                       var_smoothing=s, \n",
    "                                       sample_weight=iter_weights)\n",
    "        \n",
    "        auc_results[i, j] = m[\"AUC score\"]\n",
    "        \n",
    "        if m[\"AUC score\"] > best_auc:\n",
    "            best_auc = m[\"AUC score\"]\n",
    "            best_params = {\"smooth\": s, \"weight\": w}\n",
    "\n",
    "print(f\"Optimal found: Smoothing={best_params['smooth']:.2e}, Weight={best_params['weight']:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2e78a4f",
   "metadata": {},
   "source": [
    "# HEATMAP\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(auc_results, annot=True, fmt=\".3f\", \n",
    "            xticklabels=[f\"{w:.1f}\" for w in weight_grid], \n",
    "            yticklabels=[f\"{s:.1e}\" for s in smoothing_grid])\n",
    "plt.title(\"Grid Search: AUC Score (Smoothing vs. Weed Weight)\")\n",
    "plt.xlabel(\"Hard Weed Weight\")\n",
    "plt.ylabel(\"Var Smoothing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "190d4de3",
   "metadata": {},
   "source": [
    "# Evaluation pipeline\n",
    "# 1. Prepare the final weights based on Grid Search results\n",
    "final_weights = np.ones(len(y_train))\n",
    "final_weights[hard_weed_indices] = best_params['weight']\n",
    "\n",
    "# 2. Initialize and Train the final \"Surgical\" Model\n",
    "final_nb_clf = GaussianNB(var_smoothing=best_params['smooth'])\n",
    "final_nb_clf.fit(X_train, y_train, sample_weight=final_weights)\n",
    "\n",
    "# 3. Get the Probabilities for the PR-Curve\n",
    "final_probs = final_nb_clf.predict_proba(X_test)[:, 0] # Column 0 = 'crop'\n",
    "\n",
    "# 4. Extract the Pinned Threshold from the curve (to save 11/12 crops)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, final_probs, pos_label=\"crop\")\n",
    "\n",
    "# Find the threshold for ~92% Recall\n",
    "target_recall = 0.91\n",
    "idx = np.where(recalls >= target_recall)[0][-1]\n",
    "pinned_t = thresholds[idx]\n",
    "\n",
    "# 5. Create Final Binary Predictions\n",
    "final_preds = [\"crop\" if p >= pinned_t else \"weed\" for p in final_probs]\n",
    "\n",
    "# 6. Run the Final Evaluation\n",
    "print(f\"--- FINAL MODEL PERFORMANCE (Threshold: {pinned_t:.4f}) ---\")\n",
    "results = evaluate(y_test, final_preds, y_probs=final_probs, print_cnfm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58336a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
