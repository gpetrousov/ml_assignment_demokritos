{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95781d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14581c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Path to the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import weedcrop.dataset as weedcrop_ds\n",
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "148530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = weedcrop_ds.create_dataset_list()\n",
    "ds_list;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2a109",
   "metadata": {},
   "source": [
    "# Resize images to dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d423dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def resize_img_to_dim(img_file_path, width, height):\n",
    "    \"\"\"\n",
    "    Loads image with CV2, converts to RGB, and resizes.\n",
    "    \"\"\"\n",
    "    img_bgr = cv2.imread(img_file_path) # CV2 reads in BGR by default\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (width, height))\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02953057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "min_width, min_height = 2000, 2000\n",
    "\n",
    "def find_min_dim(ds):\n",
    "    \"\"\"\n",
    "    Finds the smallest width and height in the dataset using PIL.\n",
    "    \"\"\"\n",
    "    min_width, min_height = 2000, 2000\n",
    "    for each_img in ds:\n",
    "        img = Image.open(each_img[0]) # PIL - RGB/RGBA by default\n",
    "        min_width = min(min_width, img.size[0])\n",
    "        min_height = min(min_height, img.size[1])\n",
    "\n",
    "    print(f\"Minimum resolution: {min_width, min_height}\")\n",
    "    return min_width, min_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a31ebe",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Graphs\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract HOG\n",
    "5. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a655874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def extract_hog_features(ds):\n",
    "    \n",
    "    X_hog_features, y_hog_labels = [], []\n",
    "    min_width, min_height = weedcrop_ds.find_min_dim(ds)\n",
    "    \n",
    "    for i in range(len(ds)):\n",
    "        img = cv2.imread(ds[i][0])\n",
    "        img_resized = cv2.resize(img, (min_width, min_height))\n",
    "        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        hog_features = hog(\n",
    "            img_gray,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2),\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "        # Collect features and labels\n",
    "        X_hog_features.append(hog_features)\n",
    "        y_hog_labels.append(ds[i][1])\n",
    "    return X_hog_features, y_hog_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b31099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.7 s, sys: 1.03 s, total: 38.7 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_hog, y_hog = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ae11540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_hog), len(y_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "011538cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28475655, 0.        , 0.02391007, ..., 0.18594874, 0.25146204,\n",
       "        0.25146204]),\n",
       " 'weed')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hog[0], y_hog[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee9e3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a5fd2",
   "metadata": {},
   "source": [
    "# Local Binary Pattern - LBP\n",
    "\n",
    "For each image in the dataset:\n",
    "1. Load image\n",
    "2. Convert the image to grayscale\n",
    "3. Resize the image to match min resolution\n",
    "4. Extract LBP\n",
    "5. Get the histogram of LBP\n",
    "6. Append to list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c805c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def extract_lbp_features(ds):\n",
    "    \n",
    "    X_lbp_features, y_lbp_labels = [], []\n",
    "    min_width, min_height = weedcrop_ds.find_min_dim(ds)\n",
    "    \n",
    "    for i in range(len(ds)):\n",
    "        img = cv2.imread(ds[i][0])\n",
    "        img_resized = cv2.resize(img, (min_width, min_height))\n",
    "        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)        \n",
    "\n",
    "        # Collect features and labels\n",
    "        X_lbp_features.append(lbp_hist)\n",
    "        y_lbp_labels.append(ds[i][1])\n",
    "    return X_lbp_features, y_lbp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c476e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum resolution: (360, 360)\n",
      "CPU times: user 37.8 s, sys: 1.05 s, total: 38.9 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_lbp, y_lbp = extract_hog_features(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "825c893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 1176)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_lbp), len(y_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0caa6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fc53654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def feature_fusion(super_matrix=None, feature_list=[]):\n",
    "    \"\"\" Fuses a list of features into a super-matrix. \"\"\"\n",
    "    \n",
    "    new_features = [np.array(f) for f in feature_list]\n",
    "    \n",
    "    if super_matrix is None:\n",
    "        super_matrix = np.hstack([ np.array(f) for f in feature_list ])\n",
    "        \n",
    "    else:\n",
    "        super_matrix = np.hstack([super_matrix] + new_features)\n",
    "        \n",
    "    return super_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c501af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# HSV Histograms\n",
    "\n",
    "HOG and LBP capture Shape and Texture, but they ignore Color. In weed-crop datasets, color is often the most discriminative feature (e.g., specific shades of green or the absence of green in soil).\n",
    "\n",
    "Objects are represented by RGB values.\n",
    "\n",
    "In RGB space hue and luminocity are represented as linear combination of the RGB channels. \n",
    "\n",
    "Image segmentation can be performed by value thresholding of the HSV values.\n",
    "    \n",
    "Ref: https://scikit-image.org/docs/0.25.x/auto_examples/color_exposure/plot_rgb_to_hsv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1794c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa2319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1bae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a865f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc84b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f618c4c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data-Level: Augmentation (Not just SMOTE)\n",
    "\n",
    "\"Feature engineering on the smaller class to increase its size\" is exactly what you should do, but be careful with SMOTE. SMOTE creates \"average\" versions of your 60 samples in feature space, which can sometimes just create noise.\n",
    "\n",
    "Better approach: Image Augmentation. Before extracting HOG/LBP, take your 60 crop images and create 10 new versions of each by:\n",
    "\n",
    "    Rotating them (90°, 180°, 270°).\n",
    "\n",
    "    Flipping them horizontally and vertically.\n",
    "\n",
    "    Adjusting Brightness slightly.\n",
    "\n",
    "This turns your 60 samples into 600 samples of real visual data. Extract HOG/LBP from these augmented images. This is much more robust for computer vision than purely mathematical oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22af504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
