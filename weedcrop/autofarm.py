# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/00_baseline.ipynb.

# %% auto 0
__all__ = ['ds_dir', 'transform', 'create_ds_path', 'create_image_file_list', 'create_labels_file_list', 'create_dataset_list',
           'print_ds_info', 'visualize_ds_sample', 'get_dataset_resolution_stats', 'load_image', 'resize_images',
           'prepare_ds_pipeline', 'visualize_hog_features', 'extract_hog_features_from_list', 'calculate_accuracy',
           'evaluate', 'extract_lbp_features', 'visualize_lbp_features', 'extract_lbp_features_from_list',
           'feature_fusion', 'test_imbalanced_forest_classifier', 'reduce_hog_features', 'visualize_hsv_channels',
           'visualize_hue_thresholding', 'visualize_saturation_thresholding', 'extract_hsv_features_from_list',
           'visualize_crop_samples', 'visualize_augmented_crops', 'split_dataset', 'build_augmented_train_dataset',
           'build_augmented_train_dataset_pipeline', 'experiment_gaussian_nb']

# %% ../notebooks/00_baseline.ipynb 2
import sys
import os

from pathlib import Path
import os
import json
import IPython
import matplotlib.pyplot as plt
from skimage.feature import hog
from random import randint
from PIL import Image
from skimage import data, exposure
from skimage.color import rgb2hsv
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import numpy as np
import gc
import pandas as pd
import math

# %% ../notebooks/00_baseline.ipynb 4
ds_dir = Path("../data")
ds_dir.absolute()

# %% ../notebooks/00_baseline.ipynb 5
def create_ds_path(default_path="../data"):
    """
    Returns the path to the dataset.
    
    INPUTS:
        - default_path ["../data"]: path to root directory of the dataset.
        
    OUTPUTS:
        - ds_dir: dataset directory: type(Path)
    """
    
    ds_dir = Path(default_path)
    ds_dir.absolute()
    return ds_dir

# %% ../notebooks/00_baseline.ipynb 8
def create_image_file_list(ds_dir):
    """
    Returns the dataset with the images in a list.
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
               
    OUTPUTS:
        - imgs_ds: dataset with images: type(list)
    """
    
    imgs_files = os.listdir(ds_dir.absolute() / "img")
    imgs_files_path = ds_dir / "img"

    imgs_ds = []
    for f in imgs_files:
        imgs_ds.append(os.path.join(ds_dir, f"img/{f}"))
    imgs_ds.sort()
    return imgs_ds

# %% ../notebooks/00_baseline.ipynb 11
def create_labels_file_list(ds_dir):
    """
    Returns the dataset with the labels in a list.
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
                       
    OUTPUTS:
        - lbls_ds: dataset with labels: type(list)
    """
    
    lbls_files = os.listdir(ds_dir.absolute() / "ann")
    lbls_files_path = ds_dir / "ann"

    lbls_ds = []
    for f in lbls_files:
        lbls_ds.append(os.path.join(ds_dir, f"ann/{f}"))
    lbls_ds.sort()
    return lbls_ds

# %% ../notebooks/00_baseline.ipynb 14
def create_dataset_list(ds_dir):
    """
    Returns the dataset in the format: list[<img file>, <label>]
    
    INPUTS:
        - ds_dir ["../data"]: path to root directory of the dataset.
                               
    OUTPUTS:
        - ds: dataset format: list[<img file>, <label>]
    """
    
    images_list = create_image_file_list(ds_dir)
    labels_list = create_labels_file_list(ds_dir)
    # Create dataset list[<img file>, <label>]
    ds = []
    for img, lbl in zip(images_list, labels_list):
        with open(lbl) as f:
            l = ""
            d = str(json.load(f))
            if "weed" in d:
                l = "weed"
            elif "crop" in d:
                l = "crop"
            ds.append([img, l])
    return ds

# %% ../notebooks/00_baseline.ipynb 16
def print_ds_info(ds):
    """
    Prints dataset statistics.
    
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
    """
    
    # How many of each {weed, crop}
    nof_weeds = len([row[1] for row in ds if row[1] == "weed"])
    nof_crops = len([row[1] for row in ds if row[1] == "crop"])
    print(f"Nof weed samples: {nof_weeds}")
    print(f"Nof crop samples: {nof_crops}")
    print(f"Weeds/Crops ratio: {nof_weeds/nof_crops}")

# %% ../notebooks/00_baseline.ipynb 20
from skimage import io

def visualize_ds_sample(ds):
    """
    Show a sample of the dataset images in Jupyter notebook.
    """
    
    prev_record = ""
    crop_records = list(np.where(np.array([s[1] for s in ds]) == "crop")[0])
    nof_cols, nof_rows = 3, 3
    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 12), constrained_layout=True)

    for ax in axes.flatten():
        ax.get_yaxis().set_ticks([])
        ax.get_xaxis().set_ticks([])
        record = randint(0, len(ds)-1)
        curr_record = ds[record][1]
        if prev_record == "weed":
            crop_record_index = randint(0, len(crop_records)-1)
            record = crop_records[crop_record_index]
            curr_record = ds[record][1]
            del crop_records[crop_record_index]
        prev_record = curr_record
        ax.set_xlabel(xlabel=ds[record][1], fontsize=26, fontweight="bold")
        ax.imshow(io.imread(ds[record][0]))

# %% ../notebooks/00_baseline.ipynb 24
from PIL import Image

def get_dataset_resolution_stats(ds):
    """
    Analyzes the dataset to find min, max, and average resolutions.
    
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
        
    OUTPUTS:
        - stats: Resolution statistics: type(dict)
    """
    
    widths = []
    heights = []
    
    for each_img in ds:
        with Image.open(each_img[0]) as img:
            w, h = img.size
            widths.append(w)
            heights.append(h)

    stats = {
        "min": (min(widths), min(heights)),
        "max": (max(widths), max(heights)),
        "avg": (sum(widths)//len(widths), sum(heights)//len(heights))
    }
    
    print(f"Stats: {stats}")
    return stats

# %% ../notebooks/00_baseline.ipynb 27
from skimage import io, img_as_float

def load_image(ds):
    """
    Loads images into memory and converts to float [0, 1] range.
        
    INPUTS:
        - ds: dataset stored in list[<img file>, <label>]
        
    OUTPUTS:
        - imgs: image list; images are normalized:0-1
    """
    
    imgs = []
    c = 0
    for record in ds:
        img_path = record[0]
        img = io.imread(img_path) # normalized range is 0-1
        imgs.append(img_as_float(img))
        
    return imgs

# %% ../notebooks/00_baseline.ipynb 32
from skimage.transform import resize


def resize_images(imgs, target_size=(256, 256)):
    """
    Standardizes a list of images to a uniform resolution.
        
    INPUTS:
        - imgs: standardized images in a list
        
    OUTPUTS:
        - resized_imgs: resized images in a list
    """
    
    resized_imgs = []
    for img in imgs:
        resized_imgs.append(resize(img, target_size, anti_aliasing=True))
    return resized_imgs

# %% ../notebooks/00_baseline.ipynb 36
def prepare_ds_pipeline():
    """
    Loads images into memory, resizes to target resolution.
    Returns resized images and labels lists.
        
    OUTPUTS:
        - X_rez: resized images in a list
        - y_labels: image labels in a list
    """
    
    # Create path
    ds_dir = create_ds_path()
    
    # Create ds list
    ds = create_dataset_list(ds_dir)
    
    # Load iamges to memory
    X_imgs = load_image(ds)
    
    # Resize to equal size
    X_rez = resize_images(X_imgs)
    
    # Extract labels
    y_labels = [lbl[1] for lbl in ds]
    
    return X_rez, y_labels

# %% ../notebooks/00_baseline.ipynb 45
from skimage.feature import hog
import cv2
import matplotlib.pyplot as plt
from random import sample

def visualize_hog_features(ds, n_samples=3):
    """
    Selects random samples from the dataset and visualizes their HOG 
    side-by-side with the original image.
    """
    
    min_width, min_height = 256, 256
    
    # Pick random indices
    indices = sample(range(len(ds)), n_samples)
    
    # Setup 3 rows and 2 columns
    nof_cols = 2
    nof_rows = n_samples
    fig, axes = plt.subplots(nrows=nof_rows, ncols=nof_cols, figsize=(15, 15))

    for i, axs in enumerate(axes):
        # Extract data for the chosen sample
        idx = indices[i]
        img_path = ds[idx][0]
        label = ds[idx][1]
        
        # Process image for HOG
        img = cv2.imread(img_path)
        img_resized = cv2.resize(img, (min_width, min_height))
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
        
        _, hog_visual = hog(
            img_gray,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            visualize=True
        )
        
        # UI formatting
        axs[0].get_yaxis().set_ticks([])
        axs[1].get_yaxis().set_ticks([])
        axs[0].set_xlabel(xlabel=label)
        axs[1].set_xlabel(xlabel=label)
        
        # Set images (Column 0: Original, Column 1: HOG)
        axs[0].imshow(cv2.imread(img_path))
        axs[1].imshow(hog_visual)

    plt.tight_layout()

# %% ../notebooks/00_baseline.ipynb 47
from skimage.feature import hog
from skimage.color import rgb2gray

def extract_hog_features_from_list(X_images_rgb):
    """
    Takes a list of pre-resized RGB images and returns HOG features.
    
    INPUTS:
        - X_images_rgb: list of images in memory
    
    OUTPUTS:
        - np.array(X_hog_features): Numpy array of HOG features
    """
    
    X_hog_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray using skimage
        img_gray = rgb2gray(img_rgb)

        # 2. Extract HOG
        hog_features = hog(
            img_gray,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            visualize=False
        )

        X_hog_features.append(hog_features)
        
    return np.array(X_hog_features)

# %% ../notebooks/00_baseline.ipynb 67
def calculate_accuracy(y_test, y_preds):
    """
    Simple function to calculate accuracy.
    
    INPUTS:
        - y_test: true labels
        - y_preds: predicted labels
    """
    
    accuracy = accuracy_score(y_test, y_preds)
    return accuracy

# %% ../notebooks/00_baseline.ipynb 68
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import math

def evaluate(y_test, y_preds, y_probs=None, print_cnfm=False):
    """
    Evaluates model performance using classification metrics and PR curves.
    Specifically designed to handle "crop" as the target positive class.
        
    INPUTS:
        - y_test: Ground truth labels
        - y_preds: Predicted class labels
        - y_probs: Probabilities for the "crop" class (Column 0)
        - print_cnfm: Boolean to trigger Confusion Matrix and PR Curve plots
        
    OUTPUTS:
        - metrics: Dictionary containing Accuracy, Recall, Precision, F1, and AUC
    """
    
    
    # Accuracy sklearn
    accuracy_sklearn = calculate_accuracy(y_test, y_preds)
    
    # Confusion matrix
    conf_matrix = confusion_matrix(y_test, y_preds)
    
    # Accuracy custom
    accuracy_custom = sum(conf_matrix.diagonal())/sum(conf_matrix.flatten())
    
    # Class recall
    recall_crop = conf_matrix[0][0]/conf_matrix[0].flatten().sum()
    recall_weed = conf_matrix[1][1]/conf_matrix[1].flatten().sum()

    # Class precision
    precision_crop = conf_matrix[0][0]/conf_matrix[:,0].sum()
    if math.isnan(precision_crop): precision_crop = 0
    precision_weed = conf_matrix[1][1]/conf_matrix[:,1].sum()

    # Class f1 score
    f1_score_crop = (2*precision_crop*recall_crop)/(precision_crop+recall_crop) if (precision_crop+recall_crop) > 0 else 0
    f1_score_weed = (2*precision_weed*recall_weed)/(precision_weed+recall_weed) if (precision_weed+recall_weed) > 0 else 0
    
    # F1 macro score
    f1_macro = (f1_score_crop + f1_score_weed) / 2
    
    metrics = {
        "Accuracy sklearn": accuracy_sklearn,
        "Accuracy custom": accuracy_custom,
        "Conf Matrix": conf_matrix,
        "Recall crop": recall_crop,
        "Recall weed": recall_weed,
        "Precision crop: (TP/(TP+FP))": precision_crop,
        "Precision weed": precision_weed,
        "F1 crop": f1_score_crop,
        "F1 weed": f1_score_weed,
        "F1 macro": f1_macro,
    }

    # AUC and PR Curve
    if y_probs is not None:
        # FIX: To get AUC for "crop", we provide the probabilities and tell sklearn 
        # the order is ["weed", "crop"]. It will treat the second one as the positive class.
        # Since you pass Crop probs, we ensure they are compared against 'crop' labels.
        auc_score = roc_auc_score(y_test, y_probs)
        
        # If the score is low (0.10), it means the internal order is flipped.
        # We handle the crop-specific AUC logic here:
        if auc_score < 0.5:
            auc_score = 1 - auc_score
            
        metrics["AUC score"] = auc_score

        if print_cnfm:
            # Calculate PR Curve data - this DOES accept pos_label
            precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs, pos_label="crop")
            pr_auc = auc(recalls, precisions)

            # Plotting
            fig, ax = plt.subplots(1, 2, figsize=(15, 6))

            # Subplot 1: Confusion Matrix
            sns.heatmap(conf_matrix, annot=True, fmt="g", cmap="Blues", cbar=False, 
                        xticklabels=["crop", "weed"], yticklabels=["crop", "weed"], ax=ax[0])
            ax[0].set_title("Confusion Matrix Heatmap")
            ax[0].set_xlabel("Predicted Labels")
            ax[0].set_ylabel("True Labels")

            # Subplot 2: Precision-Recall Curve
            ax[1].plot(recalls, precisions, label=f"PR Curve (AUC = {pr_auc:.2f})", color="green")
            ax[1].set_title("Precision-Recall Curve (Crop Focus)")
            ax[1].set_xlabel("Recall (Crops Found)")
            ax[1].set_ylabel("Precision (No Weeds Misidentified)")
            ax[1].legend()
            ax[1].grid(True)
            
            plt.tight_layout()
            plt.show()
    
    elif print_cnfm:
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="g", cmap="Blues", cbar=False, 
                    xticklabels=["crop", "weed"], yticklabels=["crop", "weed"])
        plt.title("Confusion Matrix Heatmap")
        plt.show()
    
    return metrics

# %% ../notebooks/00_baseline.ipynb 91
from skimage import feature

def extract_lbp_features(ds):
    """
    DEPRECATED
    This original version uses OpenCV to laod the image. OpenCV uses the BGR color format.
    
    See newer version instead!
    """
    
    X_lbp_features, y_lbp_labels = [], []
    min_width, min_height = dataset.find_min_dim(ds)
    
    for i in range(len(ds)):
        img = cv2.imread(ds[i][0])
        img_resized = cv2.resize(img, (min_width, min_height))
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)

        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)        

        # Collect features and labels
        X_lbp_features.append(lbp_hist)
        y_lbp_labels.append(ds[i][1])
    return X_lbp_features, y_lbp_labels

# %% ../notebooks/00_baseline.ipynb 94
from skimage.feature import local_binary_pattern
import cv2
import matplotlib.pyplot as plt
import numpy as np


def visualize_lbp_features(ds):
    """
    Visualizes LBP texture histograms side-by-side with original images.
    """
    
    # 1. Setup the figure for 3 rows
    nof_rows = 3
    fig, axes = plt.subplots(nof_rows, 2, figsize=(12, 12))
    plt.subplots_adjust(hspace=0.4)

    # 2. Loop through 3 samples
    for i in range(nof_rows):
        # Load and process image
        img_path = ds[i][0]
        label = ds[i][1]
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Calculate LBP (Texture)
        # P=8, R=1, 'uniform' matches extraction function
        lbp = local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        
        # Calculate Histogram
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)

        # Plot Image
        axes[i, 0].imshow(img_rgb)
        axes[i, 0].set_title(f"Sample {i+1}: {label}")
        axes[i, 0].axis('off')

        # Plot Histogram
        axes[i, 1].bar(range(n_bins), hist, color='green', alpha=0.7)
        axes[i, 1].set_title(f"LBP Histogram (10 Features)")
        axes[i, 1].set_xlabel("Pattern Bin")
        axes[i, 1].set_ylabel("Density")
        axes[i, 1].set_ylim(0, 1)

    plt.show()

# %% ../notebooks/00_baseline.ipynb 96
from skimage import feature, color
import numpy as np

def extract_lbp_features_from_list(X_images_rgb):
    """
    Standardized LBP extraction using pre-resized RGB images.
    
    INPUTS
        - X_images_rgb: list of images in memory
        
    OUTPUTS:
        - np.array(X_lbp_features): numpy array of LBP features for each image
    """
    
    X_lbp_features = []
    
    for img_rgb in X_images_rgb:
        # 1. Convert RGB to Gray
        img_gray = color.rgb2gray(img_rgb)

        # 2. Extract LBP
        lbp = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')
        
        # 3. Create Histogram (10 bins for P=8 uniform)
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)

        X_lbp_features.append(lbp_hist)
        
    return np.array(X_lbp_features)

# %% ../notebooks/00_baseline.ipynb 109
def feature_fusion(super_matrix:np.ndarray=None, feature_list:list =[]):
    """
    Fuses multiple feature sets into a single matrix via horizontal stacking.
    Used to combine HOG, LBP, and HSV features into a unified feature vector.
    
    INPUTS:
        - super_matrix: Existing numpy matrix of features (None for first fusion)
        - feature_list: List of feature arrays to be appended to the super_matrix
        
    OUTPUTS:
        - super_matrix: Numpy matrix with features stacked horizontally per image
    """
    
    new_features = [np.array(f) for f in feature_list]
    
    if super_matrix is None:
        super_matrix = np.hstack([ np.array(f) for f in feature_list ])
        
    else:
        super_matrix = np.hstack([super_matrix] + new_features)
        
    return super_matrix

# %% ../notebooks/00_baseline.ipynb 135
from imblearn.ensemble import BalancedRandomForestClassifier

def test_imbalanced_forest_classifier(X_features:list, y_labels:list, train_split:float=0.8, class_weight=None):
    """
    Trains and evaluates a Balanced Random Forest to handle class imbalance.
    Uses stratified splitting to ensure representative class distribution in test sets.
    
    INPUTS:
        - X_features: List or array of fused features
        - y_labels: List of ground truth labels
        - train_split: Float representing the training set size ratio
        - class_weight: Optional dictionary for manual class weighting
        
    OUTPUTS:
        - metrics: Dictionary from evaluate() containing performance results
    """
    
    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(
        X_features,
        y_labels,
        train_size=train_split,
        stratify=y_labels, # Balances sets
        random_state=42
    )
    
    # Train model
    model = BalancedRandomForestClassifier(n_estimators=100, sampling_strategy="all", replacement=True, class_weight=class_weight)
    model.fit(X_train, y_train)
    
    # Run preds
    y_preds = model.predict(X_test)
    
    # Evaluate
    return evaluate(y_test, y_preds, print_cnfm=True)

# %% ../notebooks/00_baseline.ipynb 150
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def reduce_hog_features(X_hog_features, nof_components=800, fitted_scaler=None, fitted_pca=None):
    """
    Applies StandardScaler and PCA to reduce the dimensionality of HOG features.
    Supports both training mode (fitting new rules) and testing mode (applying learned rules).
    
    INPUTS:
        - X_hog_features: Matrix of HOG features to reduce
        - nof_components: Number of dimensions to keep after PCA
        - fitted_scaler: A pre-fitted StandardScaler (None for training mode)
        - fitted_pca: A pre-fitted PCA model (None for training mode)
        
    OUTPUTS:
        - X_reduced: The transformed/reduced feature matrix
        - scaler: The StandardScaler used (fitted or provided)
        - pca: The PCA model used (fitted or provided)
    """
    
    if fitted_scaler is None or fitted_pca is None:
        # --- TRAINING MODE ---
        scaler = StandardScaler()
        pca = PCA(n_components=nof_components)
        
        X_scaled = scaler.fit_transform(X_hog_features)
        X_reduced = pca.fit_transform(X_scaled)
        
        return X_reduced, scaler, pca
    else:
        # --- TESTING MODE ---
        # Use the "Rules" we learned from training
        X_scaled = fitted_scaler.transform(X_hog_features)
        X_reduced = fitted_pca.transform(X_scaled)
        
        return X_reduced

# %% ../notebooks/00_baseline.ipynb 158
from skimage.color import rgb2hsv
import cv2
import matplotlib.pyplot as plt
from random import randint

def visualize_hsv_channels(ds):
    
    """
    Visualizes Hue and Value channels side-by-side with original RGB images.
    """
    
    # 1. Setup the figure for 3 rows and 3 columns
    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))
    plt.subplots_adjust(hspace=0.4)

    for i in range(3):
        # Load and process image
        index = randint(0, len(ds)-1)
        img_path = ds[index][0]
        label = ds[index][1]
        
        # Extract image features
        bgr_img = cv2.imread(img_path)
        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
        hsv_img = rgb2hsv(rgb_img)
        
        hue_img = hsv_img[:, :, 0]   # Hue channel
        value_img = hsv_img[:, :, 2] # Value channel

        # Plot RGB image
        axes[i, 0].imshow(rgb_img)
        axes[i, 0].set_title(f"Sample {i+1}: {label}")
        axes[i, 0].axis("off")

        # Plot Hue channel
        axes[i, 1].imshow(hue_img, cmap="hsv")
        axes[i, 1].set_title("Hue channel")
        axes[i, 1].axis("off")
        
        # Plot Value channel
        axes[i, 2].imshow(value_img, cmap="gray")
        axes[i, 2].set_title("Value channel")
        axes[i, 2].axis("off")

    plt.tight_layout()
    plt.show()

# %% ../notebooks/00_baseline.ipynb 162
from skimage.color import rgb2hsv
import cv2
import matplotlib.pyplot as plt
from random import sample


def visualize_hue_thresholding(ds, hue_lower_bound=0.2, hue_upper_bound=0.45):
    """
    Visualizes the Hue channel histogram and the resulting binary mask
    based on the specified green-range thresholds.
    """
    
    # Setup fixed dimensions for 3 rows and 3 columns
    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))
    plt.subplots_adjust(hspace=0.4)

    # Pick 3 random indices
    indices = sample(range(len(ds)), 3)

    for i, img_index in enumerate(indices):
        img_path = ds[img_index][0]
        label = ds[img_index][1]
        
        # Extract image features
        bgr_img = cv2.imread(img_path)
        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
        hsv_img = rgb2hsv(rgb_img)
        hue_img = hsv_img[:, :, 0] # Hue channel
        
        # Apply filter
        binary_img = (hue_img > hue_lower_bound) & (hue_img < hue_upper_bound)
        
        # Plot RGB img
        axes[i, 0].imshow(rgb_img)
        axes[i, 0].set_title(f"Sample {i+1}: {label}")
        axes[i, 0].axis("off")
        
        # Plot Hue histogram
        axes[i, 1].hist(hue_img.ravel(), bins=254, range=(0, 1), color='gray')
        axes[i, 1].set_title("Hue Distribution")
        axes[i, 1].axvspan(hue_lower_bound, hue_upper_bound, color="green", alpha=0.3, label="Plant Range")
        axes[i, 1].set_xlim(0, 1)
        
        # Plot filtered image
        axes[i, 2].imshow(binary_img, cmap='gray')
        axes[i, 2].set_title("Green Mask")
        axes[i, 2].axis("off")

    plt.tight_layout()
    plt.show()

# %% ../notebooks/00_baseline.ipynb 167
from skimage.color import rgb2hsv
import cv2
import matplotlib.pyplot as plt
import numpy as np
from random import sample


def visualize_saturation_thresholding(ds, hue_lower_bound=0.2, hue_upper_bound=0.45, sat_lower=0.25):
    """
    Visualizes Saturation channel analysis and the final combined mask 
    (Hue + Saturation) to isolate plant biomass from soil.
    """
    
    # Setup fixed dimensions for 3 rows and 3 columns
    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))

    # Pick 3 random indices
    indices = sample(range(len(ds)), 3)

    for i, img_index in enumerate(indices):
        img_path = ds[img_index][0]
        label = ds[img_index][1]
        
        # Load and convert
        bgr_img = cv2.imread(img_path)
        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
        hsv_img = rgb2hsv(rgb_img)
        
        hue_img = hsv_img[:, :, 0]
        sat_img = hsv_img[:, :, 1]
        
        # Apply Combined Filter (Hue AND Saturation)
        # Filters for correct color range and minimum vividness
        combined_mask = (hue_img > hue_lower_bound) & (hue_img < hue_upper_bound) & (sat_img > sat_lower)
        
        # 1. Plot Saturation Grayscale Image
        axes[i, 0].imshow(sat_img, cmap="gray")
        axes[i, 0].set_title(f"Sample {i+1} Saturation: {label}")
        axes[i, 0].axis("off")

        # 2. Plot Saturation Histogram
        axes[i, 1].hist(sat_img.ravel(), bins=254, range=(0, 1), color="purple", alpha=0.6)
        axes[i, 1].set_title("Saturation Histogram")
        axes[i, 1].axvline(sat_lower, color='red', linestyle='--', label=f"Threshold: {sat_lower}")
        axes[i, 1].set_xlim(0, 1)
        axes[i, 1].legend()
        
        # 3. Plot Resulting Combined Mask
        axes[i, 2].imshow(combined_mask, cmap="viridis")
        axes[i, 2].set_title("Final Mask (Hue + Sat)")
        axes[i, 2].axis("off")

    fig.tight_layout()
    plt.show()

# %% ../notebooks/00_baseline.ipynb 171
from skimage import feature, color
import numpy as np

def extract_hsv_features_from_list(X_images_rgb, hue_lower_bound=0.2, hue_upper_bound=0.45, sat_lower=0.25, bins=10):
    """
    Extracts masked HSV histograms from a list of RGB images.
    Uses color-based thresholding to isolate plant matter from the background.
    
    INPUTS:
        - X_images_rgb: List of RGB images in memory
        - hue_lower_bound: Lower threshold for green hue (default 0.2)
        - hue_upper_bound: Upper threshold for green hue (default 0.45)
        - sat_lower: Minimum saturation to filter out gray/background (default 0.25)
        - bins: Number of histogram bins per channel
        
    OUTPUTS:
        - np.array(X_hsv_features): Numpy array of concatenated H-S-V histograms
    """
    
    X_hsv_features = []
    
    for img_rgb in X_images_rgb:
        
        # 1. Extract channels
        hsv_img = rgb2hsv(img_rgb)
        hue_chan = hsv_img[:, :, 0]
        sat_chan = hsv_img[:, :, 1]
        val_chan = hsv_img[:, :, 2]

        # 2. Build mask
        hsv_mask = (hue_chan > hue_lower_bound) & (hue_chan < hue_upper_bound) & (sat_chan > sat_lower)
        
        # 3. Apply mask
        plant_hue = hue_chan[hsv_mask]
        plant_sat = sat_chan[hsv_mask]
        plant_val = val_chan[hsv_mask]

        # 4. Create Histogram for each channel
        if plant_hue.size > 0:
            hue_hist, _ = np.histogram(plant_hue, bins=bins, range=(0, 1), density=True)
            sat_hist, _ = np.histogram(plant_sat, bins=bins, range=(0, 1), density=True)
            val_hist, _ = np.histogram(plant_val, bins=bins, range=(0, 1), density=True)
        else:
#             print("Zeroed image")
            hue_hist = np.zeros(bins)
            sat_hist = np.zeros(bins)
            val_hist = np.zeros(bins)

        # 5. Combine channels into one vector
        hsv_vector = np.concatenate([hue_hist, sat_hist, val_hist]) # Flat
        
        # 6. Append to feature list
        X_hsv_features.append(hsv_vector)
        
    return np.array(X_hsv_features)

# %% ../notebooks/00_baseline.ipynb 207
import matplotlib.pyplot as plt

def visualize_crop_samples(train_crop_images, rows=3, cols=5):
    """
    Visualizes a fragment of the crop images, specifically 3 rows.
    """
    
    # Force 3 rows
    rows = rows
    num_to_show = rows * cols
    
    # Slice the list to only handle what we need
    display_images = train_crop_images[:num_to_show]

    fig, axes = plt.subplots(rows, cols, figsize=(40, rows * 7))
    axes = axes.flatten()

    for i in range(num_to_show):
        if i < len(display_images):
            axes[i].imshow(display_images[i])
            axes[i].set_title(f"Crop Sample: {i}", fontsize=20)
            axes[i].axis('off')

    # Hide any remaining axes if the list is shorter than rows*cols
    for j in range(len(display_images), len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

# %% ../notebooks/00_baseline.ipynb 210
import albumentations as A

# %% ../notebooks/00_baseline.ipynb 211
# Parameters as found online
transform = A.Compose([
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=30, p=0.2),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.GaussianBlur(blur_limit=(3, 5), p=0.1),
#     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
    A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
])

transform.set_random_seed(42)

# %% ../notebooks/00_baseline.ipynb 215
import matplotlib.pyplot as plt

def visualize_augmented_crops(train_crop_aug, n_rows=3, cols=5):
    """
    Visualizes a fragment of the augmented crop images.
    Filters the input list to display only a specified number of rows.
    """
    
    # Calculate total images to show based on requested rows
    num_to_show = n_rows * cols
    
    # Initialize the figure with the restricted row count
    fig, axes = plt.subplots(n_rows, cols, figsize=(40, n_rows * 7))
    axes = axes.flatten()

    for i in range(num_to_show):
        if i < len(train_crop_aug):
            # Accessing the "image" key from your augmentation dictionary
            axes[i].imshow(train_crop_aug[i]["image"])
            axes[i].set_title(f"Augmented Crop: {i}", fontsize=20)
            axes[i].axis('off')
        else:
            # Hide axes if the dataset is smaller than n_rows * cols
            axes[i].axis('off')

    plt.tight_layout()
    plt.show()

# %% ../notebooks/00_baseline.ipynb 219
from sklearn.model_selection import train_test_split


def split_dataset(X_rez, y_labels, train_size=0.8):
    """
    Split data set in: X_train, X_test, y_train, y_test.
    """
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_rez,
        y_labels,
        train_size=train_size,
        stratify=y_labels, # Balances sets
        random_state=42
    )
    return X_train, X_test, y_train, y_test

# %% ../notebooks/00_baseline.ipynb 220
import albumentations as A


def build_augmented_train_dataset(X_train_orig, y_train_orig, transform=None, nof_transforms=3):
    """
    Builds an augmented training dataset by oversampling the "crop" class.
    Applies geometric and color transformations to balance class distribution.
    
    INPUTS:
        - X_train_orig: List of original RGB training images
        - y_train_orig: List of original training labels
        - transform: Albumentations pipeline (uses default if None)
        - nof_transforms: Number of augmented versions to create per crop image
        
    OUTPUTS:
        - X_train_aug: List containing original images plus augmented crops
        - y_train_aug: Updated list of labels for the augmented dataset
    """
    
    X_train_aug = []
    y_train_aug = []
    
    if not transform:
        transform = A.Compose([
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=20, p=0.3),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.GaussianBlur(blur_limit=(3, 5), p=0.1),
    #     A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),  
        A.GaussNoise(std_range=(0.04, 0.2), p=0.2),
        ])
    transform.set_random_seed(42)
    
    # Loop through the original split
    for img, label in zip(X_train_orig, y_train_orig):
        if label == "weed":
            # Keep weeds as they are
            X_train_aug.append(img)
            y_train_aug.append("weed")
        else:
            # It's a crop! 
            # Add the original
            X_train_aug.append(img)
            y_train_aug.append("crop")

            # Augment/Transform
            for _ in range(nof_transforms):
                aug_img = transform(image=img.astype("float32"))["image"]
                # Convert back to uint8 for feature extraction later
                aug_img = np.clip(aug_img, 0, 255).astype("uint8")

                X_train_aug.append(aug_img)
                y_train_aug.append("crop")
                
    return X_train_aug, y_train_aug

# %% ../notebooks/00_baseline.ipynb 225
def build_augmented_train_dataset_pipeline(X_rez, y_labels, train_size=0.8, transform=None, nof_transforms=3):
    """
    Orchestrates the split-then-augment workflow to ensure a valid evaluation.
    Splits the data into training and test sets, then augments only the 
    training portion to address class imbalance.
        
    INPUTS:
        - X_rez: List of resized images in memory
        - y_labels: List of original image labels
        - train_size: Float representing the proportion of data for training
        - transform: Albumentations pipeline for augmentation
        - nof_transforms: Number of augmented copies to generate per "crop" image
        
    OUTPUTS:
        - X_train_aug: Augmented training images
        - X_test: Original (non-augmented) test images
        - y_train_aug: Labels for the augmented training set
        - y_test: Labels for the test set
    """
    
    # Split datasets
    X_train, X_test, y_train, y_test = split_dataset(X_rez, y_labels, train_size=train_size)
    
    # Call augmentations
    X_train_aug, y_train_aug = build_augmented_train_dataset(X_train, y_train, transform=transform, nof_transforms=nof_transforms)
    
    # Return augmented ds
    return X_train_aug, X_test, y_train_aug, y_test

# %% ../notebooks/00_baseline.ipynb 268
from sklearn.naive_bayes import GaussianNB

# %% ../notebooks/00_baseline.ipynb 289
def experiment_gaussian_nb(X_train, y_train, X_test, y_test, var_smoothing=0.13, sample_weight=None, name="GNB"):
    """
    Executes a specific Gaussian Naive Bayes (GNB) experiment.
    Allows for tuning of the variance smoothing parameter and class-specific sample weights.
    Gathers experimental results from grid search optimization.
    
    INPUTS:
        - X_train, y_train: Training features and labels
        - X_test, y_test: Test features and labels
        - var_smoothing: Portion of the largest variance of all features added to variances for calculation stability
        - sample_weight: Individual weights for training samples (used to handle class imbalance)
        - name: Label for the specific experiment run
        
    OUTPUTS:
        - metrics: Dictionary of evaluation results
        - probs: The raw 'crop' class probabilities for threshold tuning
    """
    
    # Initialize specific GNB model
    gnb = GaussianNB(var_smoothing=var_smoothing)
    
    # Fit with optional sample weights
    gnb.fit(X_train, y_train, sample_weight=sample_weight)
    
    # Generate predictions and probabilities
    preds = gnb.predict(X_test)
    # Column 0 is crop
    probs = gnb.predict_proba(X_test)[:, 0]
    
    # Evaluate
    metrics = evaluate(y_test, preds, y_probs=probs, print_cnfm=False)
    metrics["Experiment"] = name
    
    return metrics, preds, probs
